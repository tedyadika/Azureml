{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tedyadika/Azureml/blob/main/3_Data_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Azure ML SDK modules"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "T_ye80Wrx_Md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Datastore,Dataset,Experiment,Run"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1675190847694
        },
        "id": "o3kPGrupx_Mh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import python modules"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "-SbAABKtx_Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import datetime\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import date,timedelta\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190847925
        },
        "id": "-2LblxXHx_Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_read ='COUNTRY_PICKS_DATA'\n",
        "filter_column ='ORDTYP_map'\n",
        "filter_value = \"ECOMM\"\n",
        "col_lag_list = ['NBR_ORDERS','SUM_QTY_TOTAL_PICKS','SUM_QTY_PIECE_PICKS']\n",
        "split_column= 'COUNTRY_NAME'\n",
        "target_column = 'SUM_QTY_PIECE_PICKS'\n",
        "cols_drop = ['SUM_QTY_PIECE_PICKS','NBR_ORDERS','SUM_QTY_TOTAL_PICKS']\n",
        "user_name = 'ADIKA'\n",
        "experiment_name = ''\n",
        "threshold= 0.1\n",
        "name =''"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190848253
        },
        "id": "ctA6q540gSKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up and data import "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "3fli2ssOx_Mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.get(name= 'dscglobalceedamlt',\n",
        "                    subscription_id= '8b20e38c-72fb-4030-a702-128e713479ca',\n",
        "                    resource_group= 'DSCGlobalCEEDTANLTst')\n",
        "\n",
        "az_store= Datastore.get(ws,'dscglobalceedamlsat_datastore')\n",
        "az_dataset= Dataset.get_by_name(ws,data_read)\n",
        "az_default_store = ws.get_default_datastore()\n",
        "dataset =az_dataset.to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190849098
        },
        "id": "XCDFwqmtx_Ml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "004218e0-7547-4289-ffef-e4968db8a9f7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter the dataset"
      ],
      "metadata": {
        "id": "2tIszGnqv02e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset.copy()\n",
        "if filter_column and filter_value !=None:\n",
        "    df = df.query(f'{filter_column}  == \"{filter_value}\"')\n",
        "elif filter_column and filter_value == None:\n",
        "    output_log = 'NO_FILTER APPLIED'\n",
        "    experiment_run.log(output_log)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "id": "fA16C9x6zqvL",
        "gather": {
          "logged": 1675190849578
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### spliting our data by country "
      ],
      "metadata": {
        "id": "drvCKgQcDG6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if split_column !=None:\n",
        "    df_list = []\n",
        "    for name, group in df.groupby(split_column):\n",
        "      df_list.append(group)\n",
        "elif split_column ==None:\n",
        "    print('Data wont be split')\n",
        "    df_list.append(df)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190849953
        },
        "id": "przSSsxfx_Mp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding importang parameters to our data"
      ],
      "metadata": {
        "id": "FVfEwKbsDVJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_values(data):\n",
        "    #data = df.copy()\n",
        "    data['DATE'] = pd.to_datetime(data['DATE'],format ='%Y-%m-%d', errors='coerce')\n",
        "    data.sort_values('DATE', inplace=True)\n",
        "    data['Month'] = [i.month for i in data['DATE']]\n",
        "    data['Year'] = [i.year for i in data['DATE']]\n",
        "    data['WEEK_YEAR'] = data['DATE'].dt.isocalendar().week \n",
        "    data['day_of_week'] = data['DATE'].dt.dayofweek\n",
        "    data['DAY_YEAR'] = data['DATE'].dt.dayofyear\n",
        "    data['DATE_N'] = data['DATE'].apply(lambda x:x.toordinal())\n",
        "    data[\"WEEK_YEAR\"] = data[\"WEEK_YEAR\"].astype('int64').astype('int64')\n",
        "    return(data)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190850141
        },
        "id": "mmc5cQUwx_Mq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding Lags"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "pDctbxLVx_Mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for data in df_list:\n",
        "  data.sort_values('DATE', inplace=True)\n",
        "  data['logarithm_base2'] = np.log10(data[target_column])\n",
        "  data['MA14'] = data[target_column].shift(14).rolling(7).mean()\n",
        "  data['MA7'] = data[target_column].shift(7).rolling(14).mean()\n"
      ],
      "metadata": {
        "id": "yJjKhSHbmskL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lag = [7,14,21,28,35]\n",
        "def add_lags(df_list,column_list,lag_list):\n",
        "  for i in range(len(df_list)):\n",
        "      df = df_list[i]#for df in df_list:\n",
        "      df = df.dropna(subset=['DATE'])\n",
        "      add_values(df)\n",
        "      for col in col_lag_list:\n",
        "        for l in lag:\n",
        "          new_col_name = col + '_lag_' + str(l)\n",
        "          new_col_name2 = col + '_mean_' + str(l)\n",
        "          df_list[i][new_col_name] = df_list[i][col].shift(l)\n",
        "          df_list[i][new_col_name2] = df_list[i][col].shift(l).rolling(7).mean()\n",
        "          #df_list[i] = df_list[i].fillna(df.mean())\n",
        "\n",
        "\n",
        "add_lags(df_list,col_lag_list,lag)\n"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "id": "CcIY-zk7Utla",
        "gather": {
          "logged": 1675190851151
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resampling data and droping columns \n",
        "in this function we resample our data on weekly basis  add date values, drop unwanted columns ,\n",
        "drop columns with very low correlation and fill nan with mean "
      ],
      "metadata": {
        "id": "GLBISg23Sows"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keep_columns =['DATE','Month','Year','WEEK_YEAR','day_of_week','DAY_YEAR','DATE_N']"
      ],
      "metadata": {
        "id": "zyG5ytm-HXyK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_columns(dataframe, keep_columns, threshold):\n",
        "    for column in dataframe.columns:\n",
        "        if column not in keep_columns and dataframe[column].dtype != 'object':\n",
        "            corr = dataframe[column].corr(dataframe[target_column])\n",
        "            if abs(corr) < threshold:\n",
        "                dataframe = dataframe.drop(column, axis=1)\n",
        "    return dataframe\n"
      ],
      "metadata": {
        "id": "Yz9rN4WyHWHq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if split_column != None:\n",
        "  for i in range(len(df_list)):\n",
        "    ml_data = df_list[i].copy()\n",
        "    drop_columns(ml_data, keep_columns, threshold)\n",
        "    name = ml_data[split_column].unique()\n",
        "    ml_data = ml_data.drop(cols_drop, axis=1)\n",
        "    ml_data.reset_index(inplace = True)\n",
        "    ml_data[split_column] = name[0]\n",
        "    ml_data=ml_data.mask(ml_data==0).fillna(ml_data.mean())\n",
        "\n",
        "    try:\n",
        "        Dataset.Tabular.register_pandas_dataframe(dataframe = ml_data,\n",
        "                                               target = az_store,\n",
        "                                               name = name[0]+'PRED_DATA_'+ experiment_name + user_name,\n",
        "                                                description=name[0]+'READY FOR ML')\n",
        "    except Exception as ex:\n",
        "        print('Error register_pandas_dataframe: ', ex)\n",
        "elif split_column == None:\n",
        "   for i in range(len(df_list)):\n",
        "    ml_data = df_list[i].copy()\n",
        "    drop_columns(ml_data, keep_columns, threshold)\n",
        "    ml_data = ml_data.drop(cols_drop, axis=1)\n",
        "    ml_data.reset_index(inplace = True)\n",
        "    ml_data[split_column] = name[0]\n",
        "    ml_data=ml_data.mask(ml_data==0).fillna(ml_data.mean())\n",
        "\n",
        "    try:\n",
        "        Dataset.Tabular.register_pandas_dataframe(dataframe = ml_data,\n",
        "                                               target = az_store,\n",
        "                                               name = name+'PREP_DATA_'+ experiment_name + user_name,\n",
        "                                                description=name[0]+'READY FOR ML')\n",
        "    except Exception as ex:\n",
        "        print('Error register_pandas_dataframe: ', ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-59f0836079b1>:9: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
            "  ml_data=ml_data.mask(ml_data==0).fillna(ml_data.mean())\n",
            "<ipython-input-27-59f0836079b1>:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  ml_data=ml_data.mask(ml_data==0).fillna(ml_data.mean())\n",
            "Message: rslex failed, falling back to clex.\n",
            "Payload: {\"pid\": 130, \"source\": \"azureml.dataprep\", \"version\": \"\", \"trace\": \"azureml|data|dataset_factory.py, line 655 in function register_pandas_dataframe.\\nazureml|data|_loggerfactory.py, line 132 in function wrapper.\\n<ipython-input-27-59f0836079b1>, line 12 in function <module>.\", \"subscription\": \"\", \"run_id\": \"\", \"resource_group\": \"\", \"workspace_name\": \"\", \"experiment_id\": \"\", \"location\": \"\", \"rslex_version\": \"2.16.1\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/50cb1500-9df2-4753-ba3f-8a43997dd1c9/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
            "<ipython-input-27-59f0836079b1>:9: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
            "  ml_data=ml_data.mask(ml_data==0).fillna(ml_data.mean())\n",
            "<ipython-input-27-59f0836079b1>:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  ml_data=ml_data.mask(ml_data==0).fillna(ml_data.mean())\n",
            "Message: rslex failed, falling back to clex.\n",
            "Payload: {\"pid\": 130, \"source\": \"azureml.dataprep\", \"version\": \"\", \"trace\": \"azureml|data|dataset_factory.py, line 655 in function register_pandas_dataframe.\\nazureml|data|_loggerfactory.py, line 132 in function wrapper.\\n<ipython-input-27-59f0836079b1>, line 12 in function <module>.\", \"subscription\": \"\", \"run_id\": \"\", \"resource_group\": \"\", \"workspace_name\": \"\", \"experiment_id\": \"\", \"location\": \"\", \"rslex_version\": \"2.16.1\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created and registered a new dataset.\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/25a5a726-9ec5-467d-bc9b-80e7ff224a4e/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
            "<ipython-input-27-59f0836079b1>:9: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
            "  ml_data=ml_data.mask(ml_data==0).fillna(ml_data.mean())\n",
            "<ipython-input-27-59f0836079b1>:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  ml_data=ml_data.mask(ml_data==0).fillna(ml_data.mean())\n",
            "Message: rslex failed, falling back to clex.\n",
            "Payload: {\"pid\": 130, \"source\": \"azureml.dataprep\", \"version\": \"\", \"trace\": \"azureml|data|dataset_factory.py, line 655 in function register_pandas_dataframe.\\nazureml|data|_loggerfactory.py, line 132 in function wrapper.\\n<ipython-input-27-59f0836079b1>, line 12 in function <module>.\", \"subscription\": \"\", \"run_id\": \"\", \"resource_group\": \"\", \"workspace_name\": \"\", \"experiment_id\": \"\", \"location\": \"\", \"rslex_version\": \"2.16.1\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created and registered a new dataset.\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/61d53b97-ddce-4959-9f23-6f486368ec7d/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
            "<ipython-input-27-59f0836079b1>:9: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
            "  ml_data=ml_data.mask(ml_data==0).fillna(ml_data.mean())\n",
            "<ipython-input-27-59f0836079b1>:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  ml_data=ml_data.mask(ml_data==0).fillna(ml_data.mean())\n",
            "Message: rslex failed, falling back to clex.\n",
            "Payload: {\"pid\": 130, \"source\": \"azureml.dataprep\", \"version\": \"\", \"trace\": \"azureml|data|dataset_factory.py, line 655 in function register_pandas_dataframe.\\nazureml|data|_loggerfactory.py, line 132 in function wrapper.\\n<ipython-input-27-59f0836079b1>, line 12 in function <module>.\", \"subscription\": \"\", \"run_id\": \"\", \"resource_group\": \"\", \"workspace_name\": \"\", \"experiment_id\": \"\", \"location\": \"\", \"rslex_version\": \"2.16.1\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created and registered a new dataset.\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/71e07aa6-4c3b-4e71-975c-428cd4e8ec18/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
            "<ipython-input-27-59f0836079b1>:9: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
            "  ml_data=ml_data.mask(ml_data==0).fillna(ml_data.mean())\n",
            "<ipython-input-27-59f0836079b1>:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  ml_data=ml_data.mask(ml_data==0).fillna(ml_data.mean())\n",
            "Message: rslex failed, falling back to clex.\n",
            "Payload: {\"pid\": 130, \"source\": \"azureml.dataprep\", \"version\": \"\", \"trace\": \"azureml|data|dataset_factory.py, line 655 in function register_pandas_dataframe.\\nazureml|data|_loggerfactory.py, line 132 in function wrapper.\\n<ipython-input-27-59f0836079b1>, line 12 in function <module>.\", \"subscription\": \"\", \"run_id\": \"\", \"resource_group\": \"\", \"workspace_name\": \"\", \"experiment_id\": \"\", \"location\": \"\", \"rslex_version\": \"2.16.1\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created and registered a new dataset.\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/5bd1dfd0-fe82-4687-b424-4797ef23062f/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n",
            "Failed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created and registered a new dataset.\n"
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190851312
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZlnLU0SgSKy",
        "outputId": "b02aa972-d651-4c06-eede-22154a316d28"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}